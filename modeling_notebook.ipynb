{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom functions for this project\n",
    "from functions import *\n",
    "\n",
    "# dataframe libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# graphing libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set_style('ticks')\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# text processing\n",
    "import nltk\n",
    "from nltk import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from textblob import TextBlob as tb\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim import matutils, models\n",
    "import scipy.sparse\n",
    "import pronouncing\n",
    "\n",
    "# modeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "# miscellany\n",
    "import re\n",
    "import string\n",
    "from collections import Counter\n",
    "import time\n",
    "import gzip\n",
    "import pickle\n",
    "\n",
    "# reload functions/libraries when edited\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# increase column width of dataframe\n",
    "pd.set_option('max_colwidth', 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to load\n",
    "with gzip.open('data/poetry_umbrella_genres_df.pkl', 'rb') as hello:\n",
    "    df = pickle.load(hello)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['poet_url', 'poem_url', 'poet', 'title', 'poem_lines', 'poem_string',\n",
       "       'genre', 'clean_lines', 'num_lines', 'num_words', 'avg_len_line',\n",
       "       'sentiment_polarity_score', 'sentiment_polarity',\n",
       "       'sentiment_subjectivity_score', 'num_end_rhymes', 'end_rhyme_ratio',\n",
       "       'end_rhyme', 'num_syllables', 'avg_syllables_word', 'lines_titled',\n",
       "       'string_titled', 'string_cleaned'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['genre', 'num_lines', 'num_words', 'avg_len_line', 'sentiment_polarity_score', 'sentiment_polarity',\n",
    "         'sentiment_subjectivity_score', 'num_end_rhymes', 'end_rhyme_ratio', 'end_rhyme', 'avg_syllables_word',\n",
    "         'lines_titled', 'string_titled', 'string_cleaned']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Let's separate our target variable and create a features dataframe \n",
    "\n",
    "target = df['genre']\n",
    "features = df[['title', 'clean_lines', 'num_lines', 'avg_len_line', 'sentiment_polarity_score', 'sentiment_polarity',\n",
    "               'sentiment_subjectivity_score', 'num_end_rhymes', 'end_rhyme_ratio']]\n",
    "\n",
    "#### Now we can drop the title and clean_lines columns\n",
    "\n",
    "features.drop(columns=['title', 'clean_lines'], inplace=True)\n",
    "features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Trim dataframe\n",
    "\n",
    "df = pd.concat([target, features], axis=1)\n",
    "df.genre.value_counts()\n",
    "\n",
    "df.genre.value_counts(normalize=True).cumsum()\n",
    "\n",
    "top8 = list(df.genre.value_counts().keys())[:8]\n",
    "top8\n",
    "\n",
    "df.shape\n",
    "\n",
    "df_top = df[df.genre.isin(top8)]\n",
    "df_top.shape\n",
    "\n",
    "df_top.genre.value_counts(normalize=True)\n",
    "\n",
    "### TF-IDF Vectorizer and a baseline model\n",
    "\n",
    "X = df_top.string_cleaned\n",
    "y = df_top.genre\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "# instantiate the vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# fit to training data and transform \n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "bnb_baseline = BernoulliNB()\n",
    "bnb_baseline.fit(X_train_vec, y_train)\n",
    "\n",
    "# predict the new document from the testing dataset\n",
    "y_preds = bnb_baseline.predict(X_test_vec)\n",
    "\n",
    "# compute the performance measures\n",
    "bnb_baseline_acc = accuracy_score(y_test, y_preds)\n",
    "bnb_baseline_f1 = f1_score(y_test, y_preds, average='weighted')\n",
    "\n",
    "print(f'Accuracy: {bnb_baseline_acc}')\n",
    "print(f'F1 score: {bnb_baseline_f1}')\n",
    "\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "print(classification_report(y_test, y_preds, target_names=list(y.unique())))\n",
    "\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "print(\"confusion matrix:\")\n",
    "print(confusion_matrix(y_test, y_preds))\n",
    "\n",
    "### Let's try vectorizing beforehand\n",
    "\n",
    "# instantiate the vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# fit to training data and transform \n",
    "X_vec = vectorizer.fit_transform(X)\n",
    "\n",
    "X = pd.DataFrame.sparse.from_spmatrix(X_vec)\n",
    "y = df_top.genre\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "bnb_baseline = BernoulliNB()\n",
    "bnb_baseline.fit(X_train, y_train)\n",
    "\n",
    "# predict the new document from the testing dataset\n",
    "y_preds = bnb_baseline.predict(X_test)\n",
    "\n",
    "# compute the performance measures\n",
    "bnb_baseline_acc = accuracy_score(y_test, y_preds)\n",
    "bnb_baseline_f1 = f1_score(y_test, y_preds, average='weighted')\n",
    "\n",
    "print(f'Accuracy: {bnb_baseline_acc}')\n",
    "print(f'F1 score: {bnb_baseline_f1}')\n",
    "\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "print(classification_report(y_test, y_preds, target_names=list(y.unique())))\n",
    "\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "print(\"confusion matrix:\")\n",
    "print(confusion_matrix(y_test, y_preds))\n",
    "\n",
    "### Let's try with our numerical data\n",
    "\n",
    "X = df_top.drop(columns=['genre', 'sentiment_polarity', 'lines_titled', 'string_titled'])\n",
    "y = df_top.genre\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "# instantiate the vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# fit to training data and transform \n",
    "X_train_vec = vectorizer.fit_transform(X_train.string_cleaned)\n",
    "X_test_vec = vectorizer.transform(X_test.string_cleaned)\n",
    "\n",
    "X_train_vec\n",
    "\n",
    "X_train_vec_df = pd.DataFrame.sparse.from_spmatrix(X_train_vec)\n",
    "X_test_vec_df = pd.DataFrame.sparse.from_spmatrix(X_test_vec)\n",
    "\n",
    "X_train_nums = X_train.drop(columns=['string_cleaned'])\n",
    "X_test_nums = X_test.drop(columns=['string_cleaned'])\n",
    "\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_nums)\n",
    "X_test_scaled = scaler.transform(X_test_nums)\n",
    "X_train_scaled_df = pd.DataFrame(X_train_scaled)\n",
    "X_test_scaled_df = pd.DataFrame(X_test_scaled)\n",
    "\n",
    "X_train_combo = pd.concat([X_train_scaled_df, X_train_vec_df], axis=1)\n",
    "X_test_combo = pd.concat([X_test_scaled_df, X_test_vec_df], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "mnb_baseline = MultinomialNB()\n",
    "mnb_baseline.fit(X_train_combo, y_train)\n",
    "\n",
    "\n",
    "\n",
    "# predict the new document from the testing dataset\n",
    "y_preds = mnb_baseline.predict(X_test_combo)\n",
    "\n",
    "# compute the performance measures\n",
    "mnb_baseline_acc = accuracy_score(y_test, y_preds)\n",
    "mnb_baseline_f1 = f1_score(y_test, y_preds, average='weighted')\n",
    "\n",
    "print(f'Accuracy: {mnb_baseline_acc}')\n",
    "print(f'F1 score: {mnb_baseline_f1}')\n",
    "\n",
    "print(classification_report(y_test, y_preds, target_names=list(y.unique())))\n",
    "\n",
    "print(\"confusion matrix:\")\n",
    "print(confusion_matrix(y_test, y_preds))\n",
    "\n",
    "print('------------------------------')\n",
    "\n",
    "bnb_baseline = BernoulliNB()\n",
    "bnb_baseline.fit(X_train_combo, y_train)\n",
    "\n",
    "# predict the new document from the testing dataset\n",
    "y_preds = bnb_baseline.predict(X_test_combo)\n",
    "\n",
    "# compute the performance measures\n",
    "bnb_baseline_acc = accuracy_score(y_test, y_preds)\n",
    "bnb_baseline_f1 = f1_score(y_test, y_preds, average='weighted')\n",
    "\n",
    "print(f'Accuracy: {bnb_baseline_acc}')\n",
    "print(f'F1 score: {bnb_baseline_f1}')\n",
    "\n",
    "print(classification_report(y_test, y_preds, target_names=list(y.unique())))\n",
    "\n",
    "print(\"confusion matrix:\")\n",
    "print(confusion_matrix(y_test, y_preds))\n",
    "\n",
    "print('------------------------------')\n",
    "\n",
    "\n",
    "\n",
    "X = df.string_cleaned\n",
    "y = df.genre\n",
    "\n",
    "# instantiate the vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# fit to training data and transform \n",
    "X_vec = vectorizer.fit_transform(X)\n",
    "\n",
    "X = pd.DataFrame.sparse.from_spmatrix(X_vec)\n",
    "y = df.genre\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "bnb_baseline = BernoulliNB()\n",
    "bnb_baseline.fit(X_train, y_train)\n",
    "\n",
    "# predict the new document from the testing dataset\n",
    "y_preds = bnb_baseline.predict(X_test)\n",
    "\n",
    "# compute the performance measures\n",
    "bnb_baseline_acc = accuracy_score(y_test, y_preds)\n",
    "bnb_baseline_f1 = f1_score(y_test, y_preds, average='weighted')\n",
    "\n",
    "print(f'Accuracy: {bnb_baseline_acc}')\n",
    "print(f'F1 score: {bnb_baseline_f1}')\n",
    "\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "print(classification_report(y_test, y_preds, target_names=list(y.unique())))\n",
    "\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "print(\"confusion matrix:\")\n",
    "print(confusion_matrix(y_test, y_preds))\n",
    "\n",
    "\n",
    "\n",
    "len(vectorizer.vocabulary_.keys())\n",
    "\n",
    "vectorizer.vocabulary_\n",
    "\n",
    "vectorizer.idf_\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# list of text documents\n",
    "text = features.string_cleaned\n",
    "# create the transform\n",
    "vectorizer = TfidfVectorizer()\n",
    "# tokenize and build vocab\n",
    "vectorizer.fit(text)\n",
    "# summarize\n",
    "print(vectorizer.vocabulary_)\n",
    "print(vectorizer.idf_)\n",
    "# encode document\n",
    "vector = vectorizer.transform([text[0]])\n",
    "# summarize encoded vector\n",
    "print(vector.shape)\n",
    "print(vector.toarray())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
